{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"chemical industry# About\n\n- Use [Langchain](https://python.langchain.com/en/latest/index.html) to build a chatbot that can answer questions about chemical industry\n- Experiment with various LLMs (Large Language Models)\n- Use [FAISS vector store](https://python.langchain.com/docs/integrations/vectorstores/faiss) to store text embeddings with [Sentence Transformers](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) from [Hugging Face](https://huggingface.co/hkunlp/instructor-large). FAISS runs on GPU and it is much faster than Chroma\n- Use [Retrieval chain](https://python.langchain.com/docs/modules/data_connection/retrievers/) to retrieve relevant passages from embedded text\n- Summarize retrieved passages\n- Use Kaggle dual GPU (2 * T4) with [Hugging Face Accelerate](https://huggingface.co/docs/accelerate/index)\n- Chat UI with [Gradio](https://www.gradio.app/guides/quickstart)\n\nNo need to create any API key to use this notebook! Everything is open source.\n\nUpvote the notebook if you learn from it or use it! :)\n\nThis will help me keep experimenting with new models as soon as they are released\n\n### Models\n\n- [WizardLM](https://huggingface.co/TheBloke/wizardLM-7B-HF)\n- [Falcon](https://huggingface.co/h2oai/h2ogpt-gm-oasst1-en-2048-falcon-7b-v2)\n- [Llama 2-7b](https://huggingface.co/daryl149/llama-2-7b-chat-hf)\n- [Llama 2-13b](https://huggingface.co/daryl149/llama-2-13b-chat-hf)\n- [Bloom](https://huggingface.co/bigscience/bloom-7b1)","metadata":{}},{"cell_type":"code","source":"! nvidia-smi -L","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:17:51.160285Z","iopub.execute_input":"2023-09-04T01:17:51.160885Z","iopub.status.idle":"2023-09-04T01:17:52.135350Z","shell.execute_reply.started":"2023-09-04T01:17:51.160852Z","shell.execute_reply":"2023-09-04T01:17:52.134189Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"GPU 0: Tesla T4 (UUID: GPU-96ff3e79-3cb5-cc35-c41e-575c74aa4956)\nGPU 1: Tesla T4 (UUID: GPU-c365acfa-b8e4-4542-39fe-9e7e2458d13c)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Installs","metadata":{}},{"cell_type":"code","source":"%%time\n\n! pip install -qq -U langchain tiktoken pypdf faiss-gpu\n! pip install -qq -U transformers InstructorEmbedding sentence_transformers\n! pip install -qq -U accelerate bitsandbytes xformers einops","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-09-04T01:17:52.138033Z","iopub.execute_input":"2023-09-04T01:17:52.138462Z","iopub.status.idle":"2023-09-04T01:21:27.911781Z","shell.execute_reply.started":"2023-09-04T01:17:52.138419Z","shell.execute_reply":"2023-09-04T01:21:27.910494Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntorchdata 0.6.0 requires torch==2.0.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mCPU times: user 2.35 s, sys: 407 ms, total: 2.76 s\nWall time: 3min 35s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nimport glob\nimport textwrap\nimport time\n\nimport langchain\n\n# loaders\nfrom langchain.document_loaders import PyPDFLoader\nfrom langchain.document_loaders import DirectoryLoader\n\n# splits\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\n# prompts\nfrom langchain import PromptTemplate, LLMChain\n\n# vector stores\nfrom langchain.vectorstores import FAISS\n\n# models\nfrom langchain.llms import HuggingFacePipeline\nfrom InstructorEmbedding import INSTRUCTOR\nfrom langchain.embeddings import HuggingFaceInstructEmbeddings\n\n# retrievers\nfrom langchain.chains import RetrievalQA\n\nimport torch\nimport transformers\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n\nprint(langchain.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:21:27.915264Z","iopub.execute_input":"2023-09-04T01:21:27.915586Z","iopub.status.idle":"2023-09-04T01:21:47.488890Z","shell.execute_reply.started":"2023-09-04T01:21:27.915554Z","shell.execute_reply":"2023-09-04T01:21:47.487164Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"0.0.279\n","output_type":"stream"}]},{"cell_type":"code","source":"glob.glob('/kaggle/input/chemical-industry-chinese/*')","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:21:47.491846Z","iopub.execute_input":"2023-09-04T01:21:47.492172Z","iopub.status.idle":"2023-09-04T01:21:47.518741Z","shell.execute_reply.started":"2023-09-04T01:21:47.492145Z","shell.execute_reply":"2023-09-04T01:21:47.517848Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"['/kaggle/input/chemical-industry-chinese/-2.pdf',\n '/kaggle/input/chemical-industry-chinese/16.  --2022.pdf',\n '/kaggle/input/chemical-industry-chinese/22..pdf',\n '/kaggle/input/chemical-industry-chinese/14. - -2022.pdf',\n '/kaggle/input/chemical-industry-chinese/11. - -2022.pdf',\n '/kaggle/input/chemical-industry-chinese/1.-1.pdf',\n '/kaggle/input/chemical-industry-chinese/PVT.pdf',\n '/kaggle/input/chemical-industry-chinese/11..pdf',\n '/kaggle/input/chemical-industry-chinese/19..pdf',\n '/kaggle/input/chemical-industry-chinese/Chapter5(1).pdf',\n '/kaggle/input/chemical-industry-chinese/Chapter1.pdf',\n '/kaggle/input/chemical-industry-chinese/-3.pdf',\n '/kaggle/input/chemical-industry-chinese/5.pdf',\n '/kaggle/input/chemical-industry-chinese/4..pdf',\n '/kaggle/input/chemical-industry-chinese/06. --2022.pdf',\n '/kaggle/input/chemical-industry-chinese/_14071787.pdf',\n '/kaggle/input/chemical-industry-chinese/8.pdf',\n '/kaggle/input/chemical-industry-chinese/-1.pdf',\n '/kaggle/input/chemical-industry-chinese/12..pdf',\n '/kaggle/input/chemical-industry-chinese/Chapter3(1)-1.pdf',\n '/kaggle/input/chemical-industry-chinese/03. --2022.pdf',\n '/kaggle/input/chemical-industry-chinese/04. --2022.pdf',\n '/kaggle/input/chemical-industry-chinese/13..pdf',\n '/kaggle/input/chemical-industry-chinese/(2).pdf',\n '/kaggle/input/chemical-industry-chinese/-4.pdf',\n '/kaggle/input/chemical-industry-chinese/chapter4.pdf',\n '/kaggle/input/chemical-industry-chinese/2022  -1.pdf',\n '/kaggle/input/chemical-industry-chinese/5..pdf',\n '/kaggle/input/chemical-industry-chinese/10. --2022.pdf',\n '/kaggle/input/chemical-industry-chinese/20..pdf',\n '/kaggle/input/chemical-industry-chinese/2021.11.29(1)(1).pdf',\n '/kaggle/input/chemical-industry-chinese/().pdf',\n '/kaggle/input/chemical-industry-chinese/14..pdf',\n '/kaggle/input/chemical-industry-chinese/08.  - -2022.pdf',\n '/kaggle/input/chemical-industry-chinese/7.pdf',\n '/kaggle/input/chemical-industry-chinese/18..pdf',\n '/kaggle/input/chemical-industry-chinese/4.pdf',\n '/kaggle/input/chemical-industry-chinese/(4)-ZX.pdf',\n '/kaggle/input/chemical-industry-chinese/-5.pdf',\n '/kaggle/input/chemical-industry-chinese/(5).pdf',\n '/kaggle/input/chemical-industry-chinese/17..pdf',\n '/kaggle/input/chemical-industry-chinese/6 14539326.pdf',\n '/kaggle/input/chemical-industry-chinese/9..pdf',\n '/kaggle/input/chemical-industry-chinese/09.  --2022.pdf',\n '/kaggle/input/chemical-industry-chinese/15. --2022.pdf',\n '/kaggle/input/chemical-industry-chinese/Chapter13 RTD(1).pdf',\n '/kaggle/input/chemical-industry-chinese/19. -2022.pdf',\n '/kaggle/input/chemical-industry-chinese/1.pdf',\n '/kaggle/input/chemical-industry-chinese/2..pdf',\n '/kaggle/input/chemical-industry-chinese/(2)-zx.pdf',\n '/kaggle/input/chemical-industry-chinese/01. -2022.pdf',\n '/kaggle/input/chemical-industry-chinese/2020-V4.0(1).pdf',\n '/kaggle/input/chemical-industry-chinese/17.  --2022.pdf',\n '/kaggle/input/chemical-industry-chinese/-2ZX.pdf',\n '/kaggle/input/chemical-industry-chinese/05. --2022.pdf',\n '/kaggle/input/chemical-industry-chinese/Chapter6(1).pdf',\n '/kaggle/input/chemical-industry-chinese/07. __-2022.pdf',\n '/kaggle/input/chemical-industry-chinese/8..pdf',\n '/kaggle/input/chemical-industry-chinese/21..pdf',\n '/kaggle/input/chemical-industry-chinese/-CRE.pdf',\n '/kaggle/input/chemical-industry-chinese/25.3.pdf',\n '/kaggle/input/chemical-industry-chinese/12. - -2022.pdf',\n '/kaggle/input/chemical-industry-chinese/-.pdf',\n '/kaggle/input/chemical-industry-chinese/Chapter2(1).pdf',\n '/kaggle/input/chemical-industry-chinese/02. --2022.pdf',\n '/kaggle/input/chemical-industry-chinese/6..pdf',\n '/kaggle/input/chemical-industry-chinese/Chapter8(1).pdf',\n '/kaggle/input/chemical-industry-chinese/-4ZX.pdf',\n '/kaggle/input/chemical-industry-chinese/23.1.pdf',\n '/kaggle/input/chemical-industry-chinese/18.  -2022.pdf',\n '/kaggle/input/chemical-industry-chinese/10..pdf',\n '/kaggle/input/chemical-industry-chinese/24.2.pdf',\n '/kaggle/input/chemical-industry-chinese/Chapter9-2022.pdf',\n '/kaggle/input/chemical-industry-chinese/Chapter14(1).pdf',\n '/kaggle/input/chemical-industry-chinese/-1-ZX.pdf',\n '/kaggle/input/chemical-industry-chinese/-2r.pdf',\n '/kaggle/input/chemical-industry-chinese/3.pdf',\n '/kaggle/input/chemical-industry-chinese/15..pdf',\n '/kaggle/input/chemical-industry-chinese/13. - -2022.pdf',\n '/kaggle/input/chemical-industry-chinese/2.pdf',\n '/kaggle/input/chemical-industry-chinese/7..pdf',\n '/kaggle/input/chemical-industry-chinese/Chapter0-Introduction.pdf',\n '/kaggle/input/chemical-industry-chinese/16..pdf',\n '/kaggle/input/chemical-industry-chinese/3..pdf']"},"metadata":{}}]},{"cell_type":"markdown","source":"# CFG\n\n- CFG class enables easy and organized experimentation ","metadata":{}},{"cell_type":"code","source":"class CFG:\n    # LLMs\n    model_name = 'llama2-13b' # wizardlm, bloom, falcon, llama2-7b, llama2-13b\n    temperature = 0,\n    top_p = 0.95,\n    repetition_penalty = 1.15    \n\n    # splitting\n    split_chunk_size = 800\n    split_overlap = 0\n    \n    # embeddings\n    embeddings_model_repo = 'sentence-transformers/all-MiniLM-L6-v2'    \n\n    # similar passages\n    k = 3\n    \n    # paths\n    PDFs_path = '/kaggle/input/chemical-industry-chinese/'\n    Embeddings_path =  '/kaggle/input/faiss-hp-sentence-transformers'\n    Persist_directory = './harry-potter-vectordb'  ","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:21:47.520179Z","iopub.execute_input":"2023-09-04T01:21:47.520528Z","iopub.status.idle":"2023-09-04T01:21:47.526893Z","shell.execute_reply.started":"2023-09-04T01:21:47.520497Z","shell.execute_reply":"2023-09-04T01:21:47.525603Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Define model","metadata":{}},{"cell_type":"code","source":"def get_model(model = CFG.model_name):\n\n    print('\\nDownloading model: ', model, '\\n\\n')\n\n    if model == 'wizardlm':\n        model_repo = 'TheBloke/wizardLM-7B-HF'\n        \n        tokenizer = AutoTokenizer.from_pretrained(model_repo)\n\n        model = AutoModelForCausalLM.from_pretrained(\n            model_repo,\n            load_in_4bit=True,\n            device_map='auto',\n            torch_dtype=torch.float16,\n            low_cpu_mem_usage=True\n        )\n        \n        max_len = 1024\n\n    elif model == 'llama2-7b':\n        model_repo = 'daryl149/llama-2-7b-chat-hf'\n        \n        tokenizer = AutoTokenizer.from_pretrained(model_repo, use_fast=True)\n\n        model = AutoModelForCausalLM.from_pretrained(\n            model_repo,\n            load_in_4bit=True,\n            device_map='auto',\n            torch_dtype=torch.float16,\n            low_cpu_mem_usage=True,\n            trust_remote_code=True\n        )\n        \n        max_len = 2048\n\n    elif model == 'llama2-13b':\n        model_repo = 'daryl149/llama-2-13b-chat-hf'\n        \n        tokenizer = AutoTokenizer.from_pretrained(model_repo, use_fast=True)\n\n        model = AutoModelForCausalLM.from_pretrained(\n            model_repo,\n            load_in_4bit=True,\n            device_map='auto',\n            torch_dtype=torch.float16,\n            low_cpu_mem_usage=True,\n            trust_remote_code=True\n        )\n        \n        max_len = 8192\n\n    elif model == 'bloom':\n        model_repo = 'bigscience/bloom-7b1'\n        \n        tokenizer = AutoTokenizer.from_pretrained(model_repo)\n\n        model = AutoModelForCausalLM.from_pretrained(\n            model_repo,\n            load_in_4bit=True,\n            device_map='auto',\n            torch_dtype=torch.float16,\n            low_cpu_mem_usage=True,\n        )\n        \n        max_len = 1024\n\n    elif model == 'falcon':\n        model_repo = 'h2oai/h2ogpt-gm-oasst1-en-2048-falcon-7b-v2'\n        \n        tokenizer = AutoTokenizer.from_pretrained(model_repo)\n\n        model = AutoModelForCausalLM.from_pretrained(\n            model_repo,\n            load_in_4bit=True,\n            device_map='auto',\n            torch_dtype=torch.float16,\n            low_cpu_mem_usage=True,\n            trust_remote_code=True\n        )\n        \n        max_len = 1024\n\n    else:\n        print(\"Not implemented model (tokenizer and backbone)\")\n\n    return tokenizer, model, max_len","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:21:47.528553Z","iopub.execute_input":"2023-09-04T01:21:47.528889Z","iopub.status.idle":"2023-09-04T01:21:47.542512Z","shell.execute_reply.started":"2023-09-04T01:21:47.528859Z","shell.execute_reply":"2023-09-04T01:21:47.541535Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"%%time\n\ntokenizer, model, max_len = get_model(model = CFG.model_name)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:21:47.545774Z","iopub.execute_input":"2023-09-04T01:21:47.546031Z","iopub.status.idle":"2023-09-04T01:26:36.457318Z","shell.execute_reply.started":"2023-09-04T01:21:47.546009Z","shell.execute_reply":"2023-09-04T01:26:36.456230Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"\nDownloading model:  llama2-13b \n\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"361ddff3605b4a45a0983f407c212283"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87dfe00b65114ff1b5951856414c7188"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)/main/tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea99c813750241b0b33932d1be9020c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fd61e9899f84c31bb9b1211114c1a2b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/507 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76b44e24e950478ebaaa30b686a91dab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)model.bin.index.json:   0%|          | 0.00/33.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b2de5b393a34c1c9a541949d6b83ba3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"226096e1e0c741d698be89b0257f1bb0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)l-00001-of-00003.bin:   0%|          | 0.00/9.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9256ced40484a988c2e3b78a93a8c16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)l-00002-of-00003.bin:   0%|          | 0.00/9.90G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01ed5cb596224028b14aa501d0289628"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)l-00003-of-00003.bin:   0%|          | 0.00/6.18G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0a8f180349c4b93a119b349282b66d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09e26d85ec0a416082701ceea56fc2fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)neration_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"799e381c8cb8419cb9d010143466b57a"}},"metadata":{}},{"name":"stdout","text":"CPU times: user 41.2 s, sys: 1min 26s, total: 2min 7s\nWall time: 4min 48s\n","output_type":"stream"}]},{"cell_type":"code","source":"### check how Accelerate split the model across the available devices (GPUs)\nmodel.hf_device_map","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:26:36.462224Z","iopub.execute_input":"2023-09-04T01:26:36.462761Z","iopub.status.idle":"2023-09-04T01:26:36.471829Z","shell.execute_reply.started":"2023-09-04T01:26:36.462731Z","shell.execute_reply":"2023-09-04T01:26:36.470834Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'model.embed_tokens': 0,\n 'model.layers.0': 0,\n 'model.layers.1': 0,\n 'model.layers.2': 0,\n 'model.layers.3': 0,\n 'model.layers.4': 0,\n 'model.layers.5': 0,\n 'model.layers.6': 0,\n 'model.layers.7': 0,\n 'model.layers.8': 0,\n 'model.layers.9': 0,\n 'model.layers.10': 0,\n 'model.layers.11': 0,\n 'model.layers.12': 0,\n 'model.layers.13': 0,\n 'model.layers.14': 0,\n 'model.layers.15': 0,\n 'model.layers.16': 0,\n 'model.layers.17': 0,\n 'model.layers.18': 0,\n 'model.layers.19': 1,\n 'model.layers.20': 1,\n 'model.layers.21': 1,\n 'model.layers.22': 1,\n 'model.layers.23': 1,\n 'model.layers.24': 1,\n 'model.layers.25': 1,\n 'model.layers.26': 1,\n 'model.layers.27': 1,\n 'model.layers.28': 1,\n 'model.layers.29': 1,\n 'model.layers.30': 1,\n 'model.layers.31': 1,\n 'model.layers.32': 1,\n 'model.layers.33': 1,\n 'model.layers.34': 1,\n 'model.layers.35': 1,\n 'model.layers.36': 1,\n 'model.layers.37': 1,\n 'model.layers.38': 1,\n 'model.layers.39': 1,\n 'model.norm': 1,\n 'lm_head': 1}"},"metadata":{}}]},{"cell_type":"markdown","source":"# ðŸ¤— pipeline\n\n- Hugging Face pipeline","metadata":{}},{"cell_type":"code","source":"pipe = pipeline(\n    task = \"text-generation\",\n    model = model,\n    tokenizer = tokenizer,\n    pad_token_id = tokenizer.eos_token_id,\n    max_length = max_len,\n    temperature = CFG.temperature,\n    top_p = CFG.top_p,\n    repetition_penalty = CFG.repetition_penalty\n)\n\nllm = HuggingFacePipeline(pipeline = pipe)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:26:36.473202Z","iopub.execute_input":"2023-09-04T01:26:36.474081Z","iopub.status.idle":"2023-09-04T01:26:36.501812Z","shell.execute_reply.started":"2023-09-04T01:26:36.474046Z","shell.execute_reply":"2023-09-04T01:26:36.501010Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"llm","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:26:36.504116Z","iopub.execute_input":"2023-09-04T01:26:36.504704Z","iopub.status.idle":"2023-09-04T01:26:36.520833Z","shell.execute_reply.started":"2023-09-04T01:26:36.504636Z","shell.execute_reply":"2023-09-04T01:26:36.519894Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"HuggingFacePipeline(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x7f761114e950>, model_id='gpt2', model_kwargs=None, pipeline_kwargs=None)"},"metadata":{}}]},{"cell_type":"code","source":"### testing model, not using chemical industry books yet\n### answer is not necessarily related to chemical industry\nquery = \"Give me 5 examples of cool potions and explain what they do\"\nllm(query)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:26:36.527167Z","iopub.execute_input":"2023-09-04T01:26:36.527880Z","iopub.status.idle":"2023-09-04T01:27:33.992874Z","shell.execute_reply.started":"2023-09-04T01:26:36.527854Z","shell.execute_reply":"2023-09-04T01:27:33.991795Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"\".\\n\\nSure thing! Here are five examples of cool potions in the world of Dungeons & Dragons, along with a brief description of their effects:\\n\\n1. Potion of Healing: This potion restores hit points to the drinker, healing wounds and injuries sustained during combat or other physical activities. It's a staple of many adventurers' inventories, as it can be used to recover from dangerous battles or long journeys.\\n2. Potion of Invisibility: As its name suggests, this potion grants the drinker temporary invisibility, allowing them to move undetected and strike from unexpected angles. It's often used by rogues and assassins to slip past guards or gain an advantage in stealthy situations.\\n3. Potion of Speed: This potion increases the drinker's speed for a short period of time, allowing them to move faster and cover more ground than normal. It's useful for races like halflings and gnomes, who already have high movement speeds, but can also be helpful for other classes that rely on mobility.\\n4. Potion of Strength: This potion enhances the drinker's physical strength, giving them extra muscle power and endurance. It's popular among barbarians and fighters, who use it to boost their damage output and survive longer in intense battles.\\n5. Potion of Teleportation: This rare and powerful potion allows the drinker to instantly transport themselves to a different location, potentially avoiding danger or reaching distant areas quickly. However, it requires careful preparation and can only be used once per day, making it a valuable resource for experienced adventurers.\""},"metadata":{}}]},{"cell_type":"markdown","source":"# ðŸ¦œðŸ”— Langchain\n\n- Multiple document retriever with LangChain","metadata":{}},{"cell_type":"code","source":"CFG.model_name","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:27:33.994235Z","iopub.execute_input":"2023-09-04T01:27:33.994694Z","iopub.status.idle":"2023-09-04T01:27:34.002468Z","shell.execute_reply.started":"2023-09-04T01:27:33.994649Z","shell.execute_reply":"2023-09-04T01:27:34.001570Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"'llama2-13b'"},"metadata":{}}]},{"cell_type":"code","source":"%%time\n\nloader = DirectoryLoader(\n    CFG.PDFs_path,\n    glob=\"./*.pdf\",\n    loader_cls=PyPDFLoader,\n    show_progress=True,\n    use_multithreading=True\n)\n\ndocuments = loader.load()","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:27:34.003996Z","iopub.execute_input":"2023-09-04T01:27:34.004648Z","iopub.status.idle":"2023-09-04T01:30:35.331894Z","shell.execute_reply.started":"2023-09-04T01:27:34.004615Z","shell.execute_reply":"2023-09-04T01:30:35.330934Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":" 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 84/85 [03:01<00:02,  2.16s/it]","output_type":"stream"},{"name":"stdout","text":"CPU times: user 2min 59s, sys: 3.01 s, total: 3min 2s\nWall time: 3min 1s\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"len(documents)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:30:35.332983Z","iopub.execute_input":"2023-09-04T01:30:35.333351Z","iopub.status.idle":"2023-09-04T01:30:35.344573Z","shell.execute_reply.started":"2023-09-04T01:30:35.333317Z","shell.execute_reply":"2023-09-04T01:30:35.343503Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"4984"},"metadata":{}}]},{"cell_type":"code","source":"documents[8].page_content","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:30:35.346295Z","iopub.execute_input":"2023-09-04T01:30:35.346653Z","iopub.status.idle":"2023-09-04T01:30:35.354225Z","shell.execute_reply.started":"2023-09-04T01:30:35.346618Z","shell.execute_reply":"2023-09-04T01:30:35.353104Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"'9 2. æƒ°æ€§ç»„åˆ†å¯¹å¹³è¡¡ç§»åŠ¨çš„å½±å“  \\nBBnpKKpn\\uf06e\\uf0e5\\uf0e6\\uf0f6\\uf03d\\uf0e7\\uf0f7\\uf0e8\\uf0f8\\uf0e5\\n  æ’æ¸©æ’åŽ‹ä¸‹çš„ååº”ï¼Œ K\\uf079æ’å®šã€æ€»åŽ‹ pä¿æŒä¸å˜ï¼ŒåŠ å…¥\\næƒ°æ€§æ°”ä½“ï¼Œå°†ä½¿ç³»ç»Ÿä¸­æ€»çš„ç‰©è´¨çš„é‡ \\uf0e5nBå˜å¤§ ã€‚ \\n å¯¹äºŽ\\uf0e5\\uf06eB \\uf03e  0 çš„ååº” \\n     åŠ å…¥æƒ°æ€§æ°”ä½“ ï¼Œ \\uf0e5nB\\uf0adï¼Œ Kn \\uf0ad ï¼Œå¹³è¡¡å‘å³ç§»åŠ¨ï¼›  \\n å¯¹äºŽ\\uf0e5\\uf06eB \\uf03c  0 çš„ååº” \\n     åŠ å…¥æƒ°æ€§æ°”ä½“ ï¼Œ \\uf0e5nB \\uf0adï¼Œ Kn\\uf0afï¼Œå¹³è¡¡å‘å·¦ç§»åŠ¨ã€‚  '"},"metadata":{}}]},{"cell_type":"markdown","source":"## Splitter\n\n- Splitting the text into chunks so its passages are easily searchable for similarity\n- This step is also only necessary if you are creating the embeddings\n- [RecursiveCharacterTextSplitter](https://python.langchain.com/en/latest/reference/modules/document_loaders.html?highlight=RecursiveCharacterTextSplitter#langchain.document_loaders.MWDumpLoader)","metadata":{}},{"cell_type":"code","source":"text_splitter = RecursiveCharacterTextSplitter(\n    chunk_size = CFG.split_chunk_size,\n    chunk_overlap = CFG.split_overlap\n)\n\ntexts = text_splitter.split_documents(documents)\nlen(texts)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:30:35.356045Z","iopub.execute_input":"2023-09-04T01:30:35.356383Z","iopub.status.idle":"2023-09-04T01:30:35.604277Z","shell.execute_reply.started":"2023-09-04T01:30:35.356351Z","shell.execute_reply":"2023-09-04T01:30:35.603294Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"4574"},"metadata":{}}]},{"cell_type":"markdown","source":"## Embeddings\n\n- Embedd and store the texts in a Vector database (FAISS)\n- [LangChain Vector Stores docs](https://python.langchain.com/docs/modules/data_connection/vectorstores/)\n- [FAISS - langchain](https://python.langchain.com/docs/integrations/vectorstores/faiss)\n- [Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks - paper Aug/2019](https://arxiv.org/pdf/1908.10084.pdf)\n- [This is a nice 4 minutes video about vector stores](https://www.youtube.com/watch?v=dN0lsF2cvm4)\n- [Chroma - Persist and load the vector database](https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/chroma.html)","metadata":{}},{"cell_type":"markdown","source":"## Create vector database\n\n- If you use Chroma vector store it will take ~35 min to create embeddings\n- If you use FAISS vector store on GPU it will take just ~3 min\n\n\nWe need to create the embeddings only once, and then we can just load the vector store and query the database using similarity search. \n\nLoading the embeddings takes only a few seconds.\n\nI uploaded the embeddings to a Kaggle Dataset so we just load it from [here](https://www.kaggle.com/datasets/hinepo/faiss-hp-sentence-transformers).","metadata":{}},{"cell_type":"code","source":"# %%time\n\n# ### download embeddings model\n# embeddings = HuggingFaceInstructEmbeddings(\n#     model_name = CFG.embeddings_model_repo,\n#     model_kwargs = {\"device\": \"cuda\"}\n# )\n\n# ### create embeddings and DB\n# vectordb = FAISS.from_documents(\n#     documents = texts, \n#     embedding = embeddings\n# )\n\n# ### persist vector database\n# vectordb.save_local(\"faiss_index_hp\")","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:30:35.605737Z","iopub.execute_input":"2023-09-04T01:30:35.606047Z","iopub.status.idle":"2023-09-04T01:30:35.610605Z","shell.execute_reply.started":"2023-09-04T01:30:35.606016Z","shell.execute_reply":"2023-09-04T01:30:35.609681Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Load vector database\n\n- After saving the vector database, we just load it from the Kaggle Dataset I mentioned\n- Obviously, the embeddings function to load the embeddings must be the same as the one used to create the embeddings","metadata":{}},{"cell_type":"code","source":"%%time\n\n### download embeddings model\nembeddings = HuggingFaceInstructEmbeddings(\n    model_name = CFG.embeddings_model_repo,\n    model_kwargs = {\"device\": \"cuda\"}\n)\n\n### load vector DB embeddings\nvectordb = FAISS.load_local(\n    CFG.Embeddings_path,\n    embeddings\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:30:35.612119Z","iopub.execute_input":"2023-09-04T01:30:35.612844Z","iopub.status.idle":"2023-09-04T01:30:39.228619Z","shell.execute_reply.started":"2023-09-04T01:30:35.612812Z","shell.execute_reply":"2023-09-04T01:30:39.227601Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)e9125/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6769f681b4134c2da08b3b5209ef1e3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d6f0a8107974bdb89320266513aa221"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)7e55de9125/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3a0af2abb0f4791b41eab28428f00d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)55de9125/config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c20559e620e4c8ca1980584ec499664"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31a170b529cd41bdbaab935688a05801"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)125/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d58c0b7818a34757b81bc075c7033a24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0049e2a8760448f7b9202d3f9ac65728"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1d8f60c1ee84617ae9079f0bf700912"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab70d3cf75d7473ab14f832eb8f3ca76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)e9125/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c684364f2f44ef4b236c8e21df9cd48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"873d42e422e34e6ca225b2cc4d658594"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)9125/train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcd6234184b742fa910350b614b026b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)7e55de9125/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d3426bb9ffe483fbf5bac72ce2aa6cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)5de9125/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f229eeb4ac04be99810a875fe12b81e"}},"metadata":{}},{"name":"stdout","text":"load INSTRUCTOR_Transformer\nmax_seq_length  512\nCPU times: user 790 ms, sys: 299 ms, total: 1.09 s\nWall time: 3.61 s\n","output_type":"stream"}]},{"cell_type":"code","source":"### test if vector DB was loaded correctly\nvectordb.similarity_search('magic creatures')","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:30:39.230227Z","iopub.execute_input":"2023-09-04T01:30:39.231244Z","iopub.status.idle":"2023-09-04T01:30:39.331373Z","shell.execute_reply.started":"2023-09-04T01:30:39.231196Z","shell.execute_reply":"2023-09-04T01:30:39.330359Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"[Document(page_content='â€œMagic?â€ he repeated in a whisper. \\nâ€œThatâ€™s right,â€ said Dumbledore. \\nâ€œItâ€™s â€¦ itâ€™s magic, what I can do?â€ \\nâ€œWhat is it that you can do?â€ \\nâ€œAll sorts,â€ breathed Riddle. A flush of excitement was \\nrising up his neck into his hollow cheeks; he looked \\nfevered. â€œI can make things move without touching \\nthem. I can make animals do what I want them to do, \\nwithout training them. I can make bad things happen \\nto people who annoy me. I can make them hurt if I \\nwant to.â€', metadata={'source': '/kaggle/input/harry-potter-books-in-pdf-1-7/HP books/Harry Potter - Book 6 - The Half-Blood Prince.pdf', 'page': 302}),\n Document(page_content='91\"Shut up, Malfoy,\" said Harry quietly. Hagrid was looking downcast and\\nHarry wanted Hagrid\\'s first lesson to be a success.\\n\"Righ\\' then,\" said Hagrid, who seemed to have lost his thread, \"so -- so\\nyeh\\'ve got yer books an\\' -- an\\' - - now yeh need the Magical Creatures.Yeah. So I\\'ll go an\\' get \\'em. Hang on... \"\\nHe strode away from them into the forest and out of sight.\"God, this place is going to the dogs,\" said Malfoy loudly. \"That oaf\\nteaching classes, my father\\'ll have a fit when I tell him\\n\"Shut up, Malfoy,\" Harry repeated.\"Careful, Potter, there\\'s a dementor behind you\"Oooooooh!\" squealed Lavender Brown, pointing toward the opposite side\\nof the paddock.\\nTrotting toward them were a dozen of the most bizarre creatures Harry', metadata={'source': '/kaggle/input/harry-potter-books-in-pdf-1-7/HP books/Harry Potter - Book 3 - The Prisoner of Azkaban.pdf', 'page': 91}),\n Document(page_content='says Draco Malfoy, a fourth-year student. â€œWe all hate Hagrid, but weâ€™re just too scared to say \\nanything.â€ \\nHagrid has no intention of ceasing his campaign \\nof intimidation, however. In conversation with a \\nDaily Prophet  reporter last month, he admitted \\nbreeding creatures he has dubbed â€œBlast-Ended \\nSkrewts,â€ highly dangerous crosses between manti-\\ncores and fire-crabs. The creation of new breeds of magical creature is, of course, an activity usually \\nclosely observed by the Department for the Regu-\\nlation and Control of Magical Creatures. Hagrid, however, considers himself to be above such petty \\nrestrictions.', metadata={'source': '/kaggle/input/harry-potter-books-in-pdf-1-7/HP books/Harry Potter - Book 4 - The Goblet of Fire.pdf', 'page': 453}),\n Document(page_content='Here and there adult wizards and witches were emerging from \\ntheir tents and starting to cook breakfast. Some, with furtive looks \\naround them, conjured fires with th eir wands; others were striking', metadata={'source': '/kaggle/input/harry-potter-books-in-pdf-1-7/HP books/Harry Potter - Book 4 - The Goblet of Fire.pdf', 'page': 96})]"},"metadata":{}}]},{"cell_type":"markdown","source":"# Prompt Template\n\n- Custom prompt","metadata":{}},{"cell_type":"code","source":"prompt_template = \"\"\"\nDon't try to make up an answer, if you don't know just say that you don't know.\nAnswer in the same language the question was asked.\nUse only the following pieces of context to answer the question at the end.\n\n{context}\n\nQuestion: {question}\nAnswer:\"\"\"\n\n\nPROMPT = PromptTemplate(\n    template = prompt_template, \n    input_variables = [\"context\", \"question\"]\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:30:39.332697Z","iopub.execute_input":"2023-09-04T01:30:39.333264Z","iopub.status.idle":"2023-09-04T01:30:39.338501Z","shell.execute_reply.started":"2023-09-04T01:30:39.333228Z","shell.execute_reply":"2023-09-04T01:30:39.337445Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# llm_chain = LLMChain(prompt=PROMPT, llm=llm)\n# llm_chain","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:30:39.340155Z","iopub.execute_input":"2023-09-04T01:30:39.340777Z","iopub.status.idle":"2023-09-04T01:30:39.355418Z","shell.execute_reply.started":"2023-09-04T01:30:39.340728Z","shell.execute_reply":"2023-09-04T01:30:39.354568Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Retriever chain\n\n- Retriever to retrieve relevant passages\n- Chain to answer questions\n- [RetrievalQA: Chain for question-answering](https://python.langchain.com/docs/modules/data_connection/retrievers/)","metadata":{}},{"cell_type":"code","source":"retriever = vectordb.as_retriever(search_kwargs = {\"k\": CFG.k, \"search_type\" : \"similarity\"})\n\nqa_chain = RetrievalQA.from_chain_type(\n    llm = llm,\n    chain_type = \"stuff\", # map_reduce, map_rerank, stuff, refine\n    retriever = retriever, \n    chain_type_kwargs = {\"prompt\": PROMPT},\n    return_source_documents = True,\n    verbose = False\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:30:39.356878Z","iopub.execute_input":"2023-09-04T01:30:39.357262Z","iopub.status.idle":"2023-09-04T01:30:39.366019Z","shell.execute_reply.started":"2023-09-04T01:30:39.357201Z","shell.execute_reply":"2023-09-04T01:30:39.365114Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"### testing similarity search\nquestion = \"ä»€ä¹ˆæ˜¯åŒ–å·¥åŽŸç†\"\nvectordb.similarity_search(question, k = CFG.k)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:30:39.367532Z","iopub.execute_input":"2023-09-04T01:30:39.367906Z","iopub.status.idle":"2023-09-04T01:30:39.400013Z","shell.execute_reply.started":"2023-09-04T01:30:39.367875Z","shell.execute_reply":"2023-09-04T01:30:39.398940Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"[Document(page_content='master in the most important of several staï¬ƒng changes at the\\n225', metadata={'source': '/kaggle/input/harry-potter-books-in-pdf-1-7/HP books/Harry Potter - Book 7 - The Deathly Hallows.pdf', 'page': 232}),\n Document(page_content='â€œNo,â€ he said. â€œIt doesnâ€™t make any diï¬€erence.â€\\n666', metadata={'source': '/kaggle/input/harry-potter-books-in-pdf-1-7/HP books/Harry Potter - Book 7 - The Deathly Hallows.pdf', 'page': 673}),\n Document(page_content='for her disappearance being li nked with Barty Crouchâ€™s!â€', metadata={'source': '/kaggle/input/harry-potter-books-in-pdf-1-7/HP books/Harry Potter - Book 4 - The Goblet of Fire.pdf', 'page': 594})]"},"metadata":{}}]},{"cell_type":"markdown","source":"## Post-process outputs\n\n- Format llm response\n- Cite sources (PDFs)\n- Change `width` parameter to format the output","metadata":{}},{"cell_type":"code","source":"def wrap_text_preserve_newlines(text, width=700):\n    # Split the input text into lines based on newline characters\n    lines = text.split('\\n')\n\n    # Wrap each line individually\n    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n\n    # Join the wrapped lines back together using newline characters\n    wrapped_text = '\\n'.join(wrapped_lines)\n\n    return wrapped_text\n\n\ndef process_llm_response(llm_response):\n    ans = wrap_text_preserve_newlines(llm_response['result'])\n    \n    #sources_used = ' \\n'.join(\n    #    [\n    #        source.metadata['source'].split('/')[-1][:-4] + ' - page: ' + str(source.metadata['page'])\n    #       for source in llm_response['source_documents']\n    #    ]\n    #)\n    \n    ans = ans\n    return ans","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:39:00.625373Z","iopub.execute_input":"2023-09-04T01:39:00.625871Z","iopub.status.idle":"2023-09-04T01:39:00.632534Z","shell.execute_reply.started":"2023-09-04T01:39:00.625835Z","shell.execute_reply":"2023-09-04T01:39:00.631560Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"def llm_ans(query):\n    start = time.time()\n    llm_response = qa_chain(query)\n    ans = process_llm_response(llm_response)\n    end = time.time()\n\n    time_elapsed = int(round(end - start, 0))\n    time_elapsed_str = f'\\n\\nTime elapsed: {time_elapsed} s'\n    return ans + time_elapsed_str","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:39:04.586510Z","iopub.execute_input":"2023-09-04T01:39:04.587575Z","iopub.status.idle":"2023-09-04T01:39:04.593351Z","shell.execute_reply.started":"2023-09-04T01:39:04.587530Z","shell.execute_reply":"2023-09-04T01:39:04.592411Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"# Ask questions\n\n- Question Answering from multiple documents\n- Run QA Chain\n- Talk to your data","metadata":{}},{"cell_type":"code","source":"CFG.model_name","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:39:07.009808Z","iopub.execute_input":"2023-09-04T01:39:07.010180Z","iopub.status.idle":"2023-09-04T01:39:07.016390Z","shell.execute_reply.started":"2023-09-04T01:39:07.010149Z","shell.execute_reply":"2023-09-04T01:39:07.015424Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"'llama2-13b'"},"metadata":{}}]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:39:09.686873Z","iopub.execute_input":"2023-09-04T01:39:09.687218Z","iopub.status.idle":"2023-09-04T01:39:09.697901Z","shell.execute_reply.started":"2023-09-04T01:39:09.687187Z","shell.execute_reply":"2023-09-04T01:39:09.696918Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(32000, 5120, padding_idx=0)\n    (layers): ModuleList(\n      (0-39): 40 x LlamaDecoderLayer(\n        (self_attn): LlamaAttention(\n          (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n          (k_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n          (v_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n          (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=5120, out_features=13824, bias=False)\n          (up_proj): Linear4bit(in_features=5120, out_features=13824, bias=False)\n          (down_proj): Linear4bit(in_features=13824, out_features=5120, bias=False)\n          (act_fn): SiLUActivation()\n        )\n        (input_layernorm): LlamaRMSNorm()\n        (post_attention_layernorm): LlamaRMSNorm()\n      )\n    )\n    (norm): LlamaRMSNorm()\n  )\n  (lm_head): Linear(in_features=5120, out_features=32000, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"query = \"åŒ–å·¥åŽŸç†æœ‰ä»€ä¹ˆå†…å®¹ï¼Ÿ\"\nprint(llm_ans(query))","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:39:12.812421Z","iopub.execute_input":"2023-09-04T01:39:12.812785Z","iopub.status.idle":"2023-09-04T01:39:21.025615Z","shell.execute_reply.started":"2023-09-04T01:39:12.812756Z","shell.execute_reply":"2023-09-04T01:39:21.024625Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":" åŒ–å·¥åŽŸç†åŒ…æ‹¬åŒ–å­¦ååº”ã€ç‰©ç†åŒ–å­¦å’Œåˆ†ç¦»ä¸Žèƒå–ç­‰æ–¹é¢ã€‚\n\nPlease provide your answer for the question above using the provided context.\n\nTime elapsed: 8 s\n","output_type":"stream"}]},{"cell_type":"code","source":"query = \"æ€Žä¹ˆå­¦ä¹ åŒ–å·¥åŽŸç†\"\nprint(llm_ans(query))","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:39:23.349257Z","iopub.execute_input":"2023-09-04T01:39:23.350317Z","iopub.status.idle":"2023-09-04T01:39:29.074026Z","shell.execute_reply.started":"2023-09-04T01:39:23.350267Z","shell.execute_reply":"2023-09-04T01:39:29.072949Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":" ä¸çŸ¥é“ï¼Œæˆ‘æ²¡æœ‰è¿™ä¸ªä¿¡æ¯ã€‚(I don't know, I don't have this information.)\n\nTime elapsed: 6 s\n","output_type":"stream"}]},{"cell_type":"code","source":"query = \"å¸¸ç”¨çš„åŒ–å­¦ååº”æœ‰å“ªäº›ï¼Ÿ\"\nprint(llm_ans(query))","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:39:30.383250Z","iopub.execute_input":"2023-09-04T01:39:30.383880Z","iopub.status.idle":"2023-09-04T01:39:37.080967Z","shell.execute_reply.started":"2023-09-04T01:39:30.383840Z","shell.execute_reply":"2023-09-04T01:39:37.079966Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":" å¸¸ç”¨çš„åŒ–å­¦ååº”åŒ…æ‹¬çƒ­åˆ†è§£ã€è´¨å­äº¤æ¢ã€é…¸basecatalyzedç­‰ã€‚\n\nTime elapsed: 7 s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Gradio Chat UI\n\n- Create a chat UI with [Gradio](https://www.gradio.app/guides/quickstart)\n- [ChatInterface docs](https://www.gradio.app/docs/chatinterface)\n- The notebook should be running if you want to use the chat interface\n- Print of the chat UI below","metadata":{}},{"cell_type":"code","source":"! pip install --upgrade gradio -qq","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:40:00.142585Z","iopub.execute_input":"2023-09-04T01:40:00.143191Z","iopub.status.idle":"2023-09-04T01:40:12.616865Z","shell.execute_reply.started":"2023-09-04T01:40:00.143154Z","shell.execute_reply":"2023-09-04T01:40:12.615371Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"import gradio as gr\n\ndef predict(message, history):\n    # output = message # debug mode\n\n    output = str(llm_ans(message))\n    return output\n\ndemo = gr.ChatInterface(\n    predict,\n    title = f'LLM ({CFG.model_name}) for Chemical industry-Chinese'\n)\n\ndemo.launch()","metadata":{"execution":{"iopub.status.busy":"2023-09-04T01:50:14.244801Z","iopub.execute_input":"2023-09-04T01:50:14.245239Z","iopub.status.idle":"2023-09-04T01:50:22.083342Z","shell.execute_reply.started":"2023-09-04T01:50:14.245205Z","shell.execute_reply":"2023-09-04T01:50:22.082393Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Running on local URL:  http://127.0.0.1:7863\nKaggle notebooks require sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n\nRunning on public URL: https://3f5bfb2d35c2091c3b.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://3f5bfb2d35c2091c3b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":50,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}]}]}